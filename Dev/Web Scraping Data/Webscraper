import os
from bs4 import BeautifulSoup
import requests

path= r'C:\Users\jere-\FinalYearProject\Dev\Web Scraping Data\ImageURLs.txt'
URLs = open(path,'r')

Animal =[]
Link =[]

for line in URLs:
    columns = line.split()
    Animal.append(columns[0])
    Link.append(columns[1])

URLs.close()

for i in range(2):
    r= requests.get(Link[i])
    soup = BeautifulSoup(r.text,'html.parser')
  

images = soup.find_all('img')
print(images,"success")





#x=len(Animal)
#print(x)
#print(Animal,Link)
#for i in range(x):
#   img_downloader(Link[i],Animal[i])



